{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp vision.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display of Multi-spectral images\n",
    "\n",
    "A multi-spectral image consists of `n` channels of spectral data, some of which may correspond to the `R`, `G`, `B` channels of visible light. For example, the Sentinel-2 satellite image data, which is the initial use case for this library, consists of 13 channels, including the 3 `RGB` channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The display support is provided by `TensorImageMS` a subclass of the FastAI `TensorImage` class. It encapsulates tensors with `n` ordered (indexed) channels of spectral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TensorImageMS(TensorImage):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a simple factory for the class which takes the tensor of ordered channels as input. The parameters `bands` and `brgtX` will be introduced shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_TensorImageMS(t: Tensor, bands: list(tuple(int))=[], brgtX: list(list(float))=[]) -> TensorImageMS:\n",
    "    return TensorImageMS(t, bands=bands, brgtX=brgtX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = create_TensorImageMS([[1.,2.],[.3,.4],[5.,6.]])\n",
    "\n",
    "test_eq(t, TensorImageMS([[1.,2.],[.3,.4],[5.,6.]]))\n",
    "test_eq(t.bands,[])\n",
    "test_eq(t.brgtX,[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple images - one for each set of channels\n",
    "\n",
    "Our approach is to display multiple images for each multi-spectral image. We can either present each channel as a single \"monochrome\" image, or more compactly, sets of 3 channels as one \"false color\" image (or as a true color image when we display the actual `RGB` channels).\n",
    "\n",
    "This is done by providing a tuple of indices corresponding to the required channels. In practice, the tuple will either be of length 3 (false color) or 1 (monochrome). A list of these \"channel tuples\" is in the `bands` attribute.\n",
    "\n",
    "The number of images in the visualization can be calculated from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def num_images(self: TensorImageMS) -> int:\n",
    "    return len(self.bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t.num_images(),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each individual image in the visualization is represented by a \"filtered\" tensor that represents the selected band(s). The following method does the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _select_bands(self: TensorImageMS, bands: tuple[int]) -> TensorImageMS:\n",
    "    assert len(bands) <= 3\n",
    "    return torch.index_select(self, 0, torch.IntTensor(bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = t._select_bands((1,0,2))\n",
    "\n",
    "test_eq(t3,TensorImageMS([[.3, .4],[1., 2.],[5.,6.]]))\n",
    "test_eq(t3.bands,t.bands)\n",
    "test_eq(t3.brgtX,t.brgtX)\n",
    "\n",
    "t1 = t._select_bands((1,))\n",
    "test_eq(t1,TensorImageMS([[.3, .4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Brightening\n",
    "\n",
    "Another practical problem that needs to be addressed when dealing with normalized Sentinel 2 images is that typical pixel values are very \"dark\" when rendered graphically.\n",
    "\n",
    "It is helpful to artificially brighten normalized tensors, using multipliers (that can vary according to the band). These multipliers lists are referenced by the `brgtX` attribute of our class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _brighten(self: TensorImageMS, brgtX: list[float]) -> TensorImageMS:\n",
    "    assert self.shape[0] == len(brgtX)\n",
    "    brdcsts = [None] * max(0, len(self.shape) - 1)\n",
    "    multX = reduce(lambda mX, _: mX.unsqueeze(-1), brdcsts, Tensor(brgtX))\n",
    "    return torch.clamp(self * multX, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1b2 = t1._brighten([2.])\n",
    "test_eq(t1b2, TensorImageMS([[0.6, 0.8]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a multiplier of `1.0` when brightening is not called for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1b1 = t1._brighten([1.])\n",
    "test_eq(t1b1, t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display on grid\n",
    "\n",
    "The brightened images are then displayed in the contexts that represent a `matplotlib` grid of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _show_tiles(self: TensorImageMS, ctxs: list, **kwargs) -> list:\n",
    "    assert ctxs is not None\n",
    "    ims: TensorImageMS = [self._select_bands(b)._brighten(m) for b, m in zip(self.bands, self.brgtX)]\n",
    "    return [show_image(im, ax=ax) for im, ax in zip(ims, ctxs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid consists of rows, one for each MS image. Each row consists of all the individual images (one per column) corresponding to channel sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_grid(self: TensorImageMS, nrows: int, **kwargs) -> list:\n",
    "    ncols = self.num_images()\n",
    "    ncells = nrows * ncols\n",
    "    return get_grid(ncells, nrows, ncols, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all put together to display the final image(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def show(self: TensorImageMS, ctxs=None, **kwargs) -> list:\n",
    "    ctxs = self._get_grid(1, **kwargs) if ctxs is None else ctxs\n",
    "    return self._show_tiles(ctxs=ctxs, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "We use the MS file io functionality defined [here](00_vision.io.ipynb) to load a multi spectral image tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(stem: str) -> str:\n",
    "    \"Get full input path for stem\"\n",
    "    return \"./images/\" + stem\n",
    "\n",
    "def tile_img_name(chn_id: str, tile_num: int) -> str:\n",
    "    \"File name from channel id and tile number\"\n",
    "    return f\"Sentinel20m-{chn_id}-20200215-{tile_num:03d}.png\"\n",
    "\n",
    "def get_channel_filenames(chn_ids, tile_idx):\n",
    "    \"Get list of all channel filenames for one tile idx\"\n",
    "    return [get_input(tile_img_name(x, tile_idx)) for x in chn_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastgs.vision.io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(tile_num: int):\n",
    "    bands=[(2,1,0),(3,)]\n",
    "    brgtX=[[3.75,4.25,4.75],[2.5]]\n",
    "    files=get_channel_filenames([\"B02\",\"B03\",\"B04\",\"B8A\"],tile_num)\n",
    "    t=read_multichan_files_as_tensor(files)\n",
    "    return TensorImageMS(t,bands=bands,brgtX=brgtX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msimg=load_tensor(66)\n",
    "msimg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animating multiple images\n",
    "\n",
    "Another possibility for display of the individual images of channel tuples is to create an animation that cycles through the images, rather than laying them out as a row of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _show_animation(self: TensorImageMS):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis(\"off\")\n",
    "    ims = [\n",
    "        [ax.imshow(self._select_bands(b)._brighten(m).permute(1, 2, 0), animated=True)]\n",
    "        for b, m in zip(self.bands, self.brgtX)\n",
    "    ]\n",
    "    anim = animation.ArtistAnimation(fig, ims, interval=1000, blit=True)\n",
    "    plt.close()\n",
    "    display(HTML(anim.to_html5_video()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that this animation has a runtime dependency on `ffmpeg` which is not listed in the package dependency. You will need to install it manually for the animation to function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not running in github actions (ffmpeg configuration issue)\n",
    "#uncomment the following line when running interactively\n",
    "\n",
    "#msimg._show_animation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reduces the amount of visual space taken up by the image, and also makes it easier to see how an individual pixel/area changes \"color\" according to the spectral channel.\n",
    "\n",
    "However, since this creates an embedded HTML movie, it results in a large increase in the cell output size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastgs] *",
   "language": "python",
   "name": "conda-env-fastgs-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
